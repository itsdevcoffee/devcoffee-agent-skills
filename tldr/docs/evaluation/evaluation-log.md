# TLDR Evaluation Log

**System Guide:** See [EVALUATION.md](./EVALUATION.md) for scoring criteria and instructions.

**Status:** Active data collection (v1.0)
**Samples Collected:** 3
**Average Score:** 9.7 / 10.0

## Summary Statistics

| Metric | Target | Current |
|--------|--------|---------|
| Average Score | >8.0 | 9.7 |
| Samples with User Feedback | - | 2 |
| Completeness Avg | >2.0 | 2.43 |
| Conciseness Avg | >2.0 | 2.43 |
| Actionability Avg | >2.0 | 2.43 |
| Accuracy Avg | >2.0 | 2.37 |

## Evaluation Samples

| ID | Date | Type | Claude Score | User Score | Status | Key Notes |
|----|------|------|--------------|------------|--------|-----------|
| 001 | 2026-02-06 | Research | 9.7 | - | Unscored | Excellent coverage, minor verbosity in process details |
| 002 | 2026-02-15 | Documentation | 9.5 | 9.9 | Scored | First URL-based TLDR; strong docs summary, minor specificity gaps |
| 003 | 2026-02-15 | Planning | 9.8 | 5.0 | Scored | Over-restructured: should preserve numbered question format, not collapse into categories |

## Notes

- Evaluation started: 2026-02-06
- Target: 10-20 samples for initial pattern analysis
- All samples are from real development work (not synthetic tests)
- Sample 002 is the first external URL summary (docs page vs conversation message)

---

*To add a new sample, see EVALUATION.md for instructions.*
